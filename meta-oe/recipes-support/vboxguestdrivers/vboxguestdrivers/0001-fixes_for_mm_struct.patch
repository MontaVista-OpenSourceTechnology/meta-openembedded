From 98070c936931879d2b8e22939724b5a0689721d0 Mon Sep 17 00:00:00 2001
From: Hongxu Jia <hongxu.jia@windriver.com>
Date: Tue, 18 Aug 2020 17:48:29 +0800
Subject: [PATCH 1/3] fixes_for_mm_struct

Upstream-Status: Backport [https://www.virtualbox.org/ticket/19644]

Signed-off-by: Hongxu Jia <hongxu.jia@windriver.com>
---
 .../Runtime/r0drv/linux/memobj-r0drv-linux.c  | 74 +++++++++++++++++--
 1 file changed, 67 insertions(+), 7 deletions(-)

diff --git a/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c b/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c
index 37389bcc..cdc7e8e6 100644
--- a/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c
+++ b/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c
@@ -222,9 +222,17 @@ static void *rtR0MemObjLinuxDoMmap(RTR3PTR R3PtrFixed, size_t cb, size_t uAlignm
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 5, 0)
         ulAddr = vm_mmap(NULL, R3PtrFixed, cb, fLnxProt, MAP_SHARED | MAP_ANONYMOUS | MAP_FIXED, 0);
 #else
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
         down_write(&pTask->mm->mmap_sem);
+#else
+        down_write(&pTask->mm->mmap_lock);
+#endif
         ulAddr = do_mmap(NULL, R3PtrFixed, cb, fLnxProt, MAP_SHARED | MAP_ANONYMOUS | MAP_FIXED, 0);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
         up_write(&pTask->mm->mmap_sem);
+#else
+        up_write(&pTask->mm->mmap_lock);
+#endif
 #endif
     }
     else
@@ -232,9 +240,17 @@ static void *rtR0MemObjLinuxDoMmap(RTR3PTR R3PtrFixed, size_t cb, size_t uAlignm
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 5, 0)
         ulAddr = vm_mmap(NULL, 0, cb, fLnxProt, MAP_SHARED | MAP_ANONYMOUS, 0);
 #else
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
         down_write(&pTask->mm->mmap_sem);
+#else
+        down_write(&pTask->mm->mmap_lock);
+#endif
         ulAddr = do_mmap(NULL, 0, cb, fLnxProt, MAP_SHARED | MAP_ANONYMOUS, 0);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
         up_write(&pTask->mm->mmap_sem);
+#else
+        up_write(&pTask->mm->mmap_lock);
+#endif
 #endif
         if (    !(ulAddr & ~PAGE_MASK)
             &&  (ulAddr & (uAlignment - 1)))
@@ -269,13 +285,29 @@ static void rtR0MemObjLinuxDoMunmap(void *pv, size_t cb, struct task_struct *pTa
     Assert(pTask == current); RT_NOREF_PV(pTask);
     vm_munmap((unsigned long)pv, cb);
 #elif defined(USE_RHEL4_MUNMAP)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
     down_write(&pTask->mm->mmap_sem);
+#else
+    down_write(&pTask->mm->mmap_lock);
+#endif
     do_munmap(pTask->mm, (unsigned long)pv, cb, 0); /* should it be 1 or 0? */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
     up_write(&pTask->mm->mmap_sem);
 #else
+    up_write(&pTask->mm->mmap_lock);
+#endif
+#else
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
     down_write(&pTask->mm->mmap_sem);
+#else
+    down_write(&pTask->mm->mmap_lock);
+#endif
     do_munmap(pTask->mm, (unsigned long)pv, cb);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
     up_write(&pTask->mm->mmap_sem);
+#else
+    up_write(&pTask->mm->mmap_lock);
+#endif
 #endif
 }
 
@@ -593,7 +625,11 @@ DECLHIDDEN(int) rtR0MemObjNativeFree(RTR0MEMOBJ pMem)
                 size_t              iPage;
                 Assert(pTask);
                 if (pTask && pTask->mm)
-                    down_read(&pTask->mm->mmap_sem);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
+		    down_read(&pTask->mm->mmap_sem);
+#else
+		    down_read(&pTask->mm->mmap_lock);
+#endif
 
                 iPage = pMemLnx->cPages;
                 while (iPage-- > 0)
@@ -608,7 +644,11 @@ DECLHIDDEN(int) rtR0MemObjNativeFree(RTR0MEMOBJ pMem)
                 }
 
                 if (pTask && pTask->mm)
-                    up_read(&pTask->mm->mmap_sem);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
+		    up_read(&pTask->mm->mmap_sem);
+#else
+		    up_read(&pTask->mm->mmap_lock);
+#endif
             }
             /* else: kernel memory - nothing to do here. */
             break;
@@ -1076,7 +1116,11 @@ DECLHIDDEN(int) rtR0MemObjNativeLockUser(PPRTR0MEMOBJINTERNAL ppMem, RTR3PTR R3P
     papVMAs = (struct vm_area_struct **)RTMemAlloc(sizeof(*papVMAs) * cPages);
     if (papVMAs)
     {
-        down_read(&pTask->mm->mmap_sem);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
+	down_read(&pTask->mm->mmap_sem);
+#else
+	down_read(&pTask->mm->mmap_lock);
+#endif
 
         /*
          * Get user pages.
@@ -1162,7 +1206,11 @@ DECLHIDDEN(int) rtR0MemObjNativeLockUser(PPRTR0MEMOBJINTERNAL ppMem, RTR3PTR R3P
                 papVMAs[rc]->vm_flags |= VM_DONTCOPY | VM_LOCKED;
             }
 
-            up_read(&pTask->mm->mmap_sem);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
+	    up_read(&pTask->mm->mmap_sem);
+#else
+	    up_read(&pTask->mm->mmap_lock);
+#endif
 
             RTMemFree(papVMAs);
 
@@ -1189,7 +1237,11 @@ DECLHIDDEN(int) rtR0MemObjNativeLockUser(PPRTR0MEMOBJINTERNAL ppMem, RTR3PTR R3P
 #endif
         }
 
-        up_read(&pTask->mm->mmap_sem);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
+	up_read(&pTask->mm->mmap_sem);
+#else
+	up_read(&pTask->mm->mmap_lock);
+#endif
 
         RTMemFree(papVMAs);
         rc = VERR_LOCK_FAILED;
@@ -1604,7 +1656,11 @@ DECLHIDDEN(int) rtR0MemObjNativeMapUser(PPRTR0MEMOBJINTERNAL ppMem, RTR0MEMOBJ p
             const size_t    cPages    = (offSub + cbSub) >> PAGE_SHIFT;
             size_t          iPage;
 
-            down_write(&pTask->mm->mmap_sem);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
+	    down_write(&pTask->mm->mmap_sem);
+#else
+	    down_write(&pTask->mm->mmap_lock);
+#endif
 
             rc = VINF_SUCCESS;
             if (pMemLnxToMap->cPages)
@@ -1721,7 +1777,11 @@ DECLHIDDEN(int) rtR0MemObjNativeMapUser(PPRTR0MEMOBJINTERNAL ppMem, RTR0MEMOBJ p
             }
 #endif /* CONFIG_NUMA_BALANCING */
 
-            up_write(&pTask->mm->mmap_sem);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 8, 0)
+	    up_write(&pTask->mm->mmap_sem);
+#else
+	    up_write(&pTask->mm->mmap_lock);
+#endif
 
             if (RT_SUCCESS(rc))
             {
-- 
2.18.2

